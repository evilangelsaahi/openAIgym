{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
    "outputId": "c4ab66d1-4a67-4b4a-ca3e-60f9cc7ee39b"
   },
   "outputs": [],
   "source": [
    "#!pip install gym\n",
    "#!pip install tensorflow\n",
    "#!pip install pyglet\n",
    "#!pip install keras\n",
    "#!pip install tf-agents\n",
    "\n",
    "#!pip install reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16e2b39-7162-403c-8197-3f26609e4d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
   "metadata": {
    "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
    "tags": []
   },
   "source": [
    "### Import gym library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f7d7d8-c25f-4070-874f-ee08289d2f93",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e616f27-90b1-40ce-b026-07a0d917a115",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b765f1-7360-4ddf-90ed-3cdb5f4cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c7c70-10c8-48e9-a5f7-56bcc01383ab",
   "metadata": {
    "id": "aa719112-e9f3-45f6-89dd-b7052aaf4895",
    "tags": []
   },
   "source": [
    "### Reset the enviornment to its initial state and return 4 values in array\n",
    "\n",
    "![Observation](obs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
    "outputId": "b6615ebc-3139-4fb7-8ba7-8ff540f55a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00260033, -0.03472597, -0.04944156, -0.00430254], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b517004-07ff-4301-9dec-93f7d221588e",
   "metadata": {
    "id": "d40c5768-22dd-4b26-b6fb-c4d27d763862"
   },
   "source": [
    "### observation_space returns the information about the environment space\n",
    "    # Box data type i.e. for continous observation\n",
    "    # returned Box object represents\n",
    "    # Box([[lower range of obs], [upper range obs], (number of dimensions), data type])\n",
    "![](env.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
    "outputId": "34ab00ef-1cd0-4235-aa48-c7364a7e14c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca2086-b302-412b-bcb9-26702a49185a",
   "metadata": {
    "id": "9ee88143-17be-49fe-ac30-dc2d22a0b5bd",
    "tags": []
   },
   "source": [
    "### action_space returns the Discrete object\n",
    "### sequence of integers, reprents the actions\n",
    "\n",
    "![](action.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
    "outputId": "da4c472a-2c8a-45a2-d251-46f6d0823b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e",
   "metadata": {
    "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e"
   },
   "outputs": [],
   "source": [
    "#env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e347e-c2b3-4f36-8593-0dc799869671",
   "metadata": {
    "id": "b2d47695-e63e-4509-b452-013b1c6da223",
    "tags": []
   },
   "source": [
    "### Termination state is reached when one of these conditions are met\n",
    "### and done parameter is set to True\n",
    "\n",
    "![](eps.png)\n",
    "\n",
    "### Here a simple demonstartion of pushing cart to one side\n",
    "### To run the cell below change cell's type from Raw to Code\n",
    "\n",
    "### To take an action we need step() function\n",
    "    # step function returns 4 parameters\n",
    "    # [[obs state], reward, terminal state(done = bool),info]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff0ddb04-12fb-4b6a-b758-8dba64dfbe68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "nZn0d4IB9TJs",
    "outputId": "497f9c3b-1ea0-42c9-f1d4-f567700bfb40",
    "tags": []
   },
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for step_index in range(10000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(\"Step {}:\".format(step_index))\n",
    "    print(\"action: {}\".format(action))\n",
    "    print(\"observation: {}\".format(observation))\n",
    "    print(\"reward: {}\".format(reward))\n",
    "    print(\"done: {}\".format(done))\n",
    "    print(\"info: {}\".format(info), end =\"\\n\\n\")\n",
    "    \n",
    "    # if termination state has been reached\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
   "metadata": {
    "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
    "tags": []
   },
   "source": [
    "### Importing the tensorflow environments\n",
    "    # they generate tensors\n",
    "    # and replay buffer can be used to train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8453fe-03ed-4862-9d7b-ba9ebd796351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00134ea1-f9e7-4111-bfd8-bd50ed648eee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running a test for average score using random actions over 100 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13982b7b-2fe2-40af-9367-d86b8a31aa41",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episodes: 100 num_steps: 2242\n",
      "avg_length 22.42 avg_reward: 22.42\n"
     ]
    }
   ],
   "source": [
    "env = suite_gym.load(env_name)\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 100\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not time_step.is_last():\n",
    "        action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "        #print(action)\n",
    "        time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        episode_reward += time_step.reward.numpy()\n",
    "    rewards.append(episode_reward)\n",
    "    steps.append(episode_steps)\n",
    "    time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa727e9e-5d0d-40a6-bf70-e342c028e46e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing Q Policy libraries for creating a Q network for policies\n",
    "    # Agents trained will be based on Deep Q-Learning network (DQN)\n",
    "    # Q is quality of given moves\n",
    "    # It Predicts Q value for each discrete action Q: State * Action --> Reward.\n",
    "    # Bellman equation is a detailed explanation of this algorithm\n",
    "![](bellman.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8168b328-1451-492b-8bc0-94eb8faa19b5",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8"
   },
   "outputs": [],
   "source": [
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import network\n",
    "from tf_agents.policies import q_policy\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9faf7ae0-71aa-4db0-bc17-4f5a118daf07",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)) \n",
      "\n",
      " Number of actions: \t 2\n"
     ]
    }
   ],
   "source": [
    "input_tensor_spec = tensor_spec.TensorSpec((4,), tf.float32)\n",
    "time_step_spec = ts.time_step_spec(input_tensor_spec)\n",
    "action_spec = tensor_spec.BoundedTensorSpec((),\n",
    "                                            tf.int32,\n",
    "                                            minimum=0,\n",
    "                                            maximum=1)\n",
    "\n",
    "num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(action_spec, \"\\n\\n Number of actions: \\t\", num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4f99fc4-f9e5-4bd5-a8cb-42d466e6d95c",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
      "Action distribution:\n",
      "tfp.distributions.Categorical(\"Categorical\", batch_shape=[2], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "class QNetwork(network.Network):\n",
    "\n",
    "    def __init__(self, input_tensor_spec, action_spec, num_actions=num_actions, name=None):\n",
    "        super(QNetwork, self).__init__(\n",
    "            input_tensor_spec=input_tensor_spec,\n",
    "            state_spec=(),\n",
    "            name=name)\n",
    "        self._sub_layers = [\n",
    "            tf.keras.layers.Dense(num_actions),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, step_type=None, network_state=()):\n",
    "        del step_type\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        for layer in self._sub_layers:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs, network_state\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "observation = tf.ones([batch_size] + time_step_spec.observation.shape.as_list())\n",
    "time_steps = ts.restart(observation, batch_size=batch_size)\n",
    "\n",
    "my_q_network = QNetwork(\n",
    "    input_tensor_spec=input_tensor_spec,\n",
    "    action_spec=action_spec)\n",
    "\n",
    "my_q_policy = q_policy.QPolicy(\n",
    "    time_step_spec, action_spec, q_network=my_q_network)\n",
    "\n",
    "action_step = my_q_policy.action(time_steps)\n",
    "distribution_step = my_q_policy.distribution(time_steps)\n",
    "\n",
    "print('Action:')\n",
    "print(action_step.action)\n",
    "\n",
    "print('Action distribution:')\n",
    "print(distribution_step.action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d05597-9901-4e46-93dd-2ccedd1b3b27",
   "metadata": {
    "id": "8e1b65d6-6e11-4280-b836-585d0e2fb079"
   },
   "source": [
    "### Importing TensorFlow Drivers\n",
    "    # There are 2 types of drivers\n",
    "    # DynamicStepDriver, which terminates after a given number of (valid) environment steps\n",
    "    # DynamicEpisodeDriver, which terminates after a given number of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c20b12-4145-40f0-9b15-7bef11231116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.drivers import dynamic_episode_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
    "outputId": "03bb33c1-65f9-4f09-917e-6a72e61b6442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_time_step TimeStep(\n",
      "{'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
      " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
      "array([[-0.02673768, -0.02472047,  0.01095815, -0.0441931 ]],\n",
      "      dtype=float32)>,\n",
      " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>})\n",
      "Number of Steps:  4807\n",
      "Number of Episodes:  100\n",
      "policy_state ()\n"
     ]
    }
   ],
   "source": [
    "num_episodes = tf_metrics.NumberOfEpisodes()\n",
    "env_steps = tf_metrics.EnvironmentSteps()\n",
    "observers = [num_episodes, env_steps]\n",
    "\n",
    "driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    tf_env, my_q_policy, observers, num_episodes=100)\n",
    "\n",
    "# Initial driver.run will reset the environment and initialize the policy.\n",
    "final_time_step, policy_state = driver.run()\n",
    "\n",
    "print('final_time_step', final_time_step)\n",
    "print('Number of Steps: ', env_steps.result().numpy())\n",
    "print('Number of Episodes: ', num_episodes.result().numpy())\n",
    "print('policy_state', policy_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f1c96-4304-44ea-98f6-ed2ade524186",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "IAYGWxX3E8-n",
    "outputId": "294924fc-0db9-4e90-85f2-11e18c8885fb",
    "tags": []
   },
   "source": [
    "### Importing Replay Buffers\n",
    "    # replay buffers are used to store trajectories of experience when executing a policy in an environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d910dae7-45a6-4a2b-89fa-2711f377e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks import q_network\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b75b466-089d-4c3c-84cf-b1782ac11c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_net = q_network.QNetwork(\n",
    "    tf_env.time_step_spec().observation,\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=(100,))\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(0.001))\n",
    "\n",
    "replay_buffer_capacity = 1000\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "# Add an observer that adds to the replay buffer:\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "collect_steps_per_iteration = 10\n",
    "collect_op = dynamic_step_driver.DynamicStepDriver(\n",
    "  tf_env,\n",
    "  agent.collect_policy,\n",
    "  observers=replay_observer,\n",
    "  num_steps=collect_steps_per_iteration).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b38c71a-1d1c-4c75-9625-e41963e62d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[-0.05139242, -0.02753681,  0.03577055,  0.01794845]],\n",
       "       dtype=float32)>,\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8428cbb-fdd4-4048-8379-d963aabf9fbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Above all cells where the basic idea of building a network and training an agent, Now we proceed by putting all together from tensorflow documentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8cca5-bf2c-4eb2-953b-24b7b1e66357",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing libraries for training the DQN C51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33fee400-5ce1-4ae2-afe8-3f9b5ad0eb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import categorical_q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00059a4-1019-4c85-81db-ff1192ceb3c2",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecda9124-69b6-42e7-a4e9-4db992279094",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\" # @param {type:\"string\"}\n",
    "num_iterations = 15000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "gamma = 0.99\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_atoms = 51  # @param {type:\"integer\"}\n",
    "min_q_value = -20  # @param {type:\"integer\"}\n",
    "max_q_value = 20  # @param {type:\"integer\"}\n",
    "n_step_update = 2  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69493925-55d0-4753-985e-a3f7ff80b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87481546-0469-47c4-a250-f3576c246509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.02556861, -0.03434043, -0.02994688, -0.02370907], dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "#PIL.Image.fromarray(env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01648881-a593-4ab0-b39a-8fa3a1bd19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9c97e90-be53-4cc0-b4e5-640e7f3e60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d2c4718-599d-4b39-81ef-7a6503d388b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a68af7d-a997-4aa5-bbcb-ed531a1a9e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4a06707-9c14-402b-b488-c3f18e73ae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.02121742,  0.03536892, -0.02512419,  0.02849847], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.0219248 ,  0.230842  , -0.02455422, -0.27200434], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:',)\n",
    "print(time_step, end=\"\\n\\n\")\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb90c9c9-7e85-4271-bec0-b789f945250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdfe4de6-b1c9-4425-a564-ab07f350cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_q_net = categorical_q_network.CategoricalQNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    num_atoms=num_atoms,\n",
    "    fc_layer_params=fc_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5f8be9c-78d3-44ca-ad6f-4f02a141d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = categorical_dqn_agent.CategoricalDqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    categorical_q_network=categorical_q_net,\n",
    "    optimizer=optimizer,\n",
    "    min_q_value=min_q_value,\n",
    "    max_q_value=max_q_value,\n",
    "    n_step_update=n_step_update,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    gamma=gamma,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82b38e1f-df96-46ae-9d7d-f00ece02da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ae88a-a27c-442f-927e-90fc0405b068",
   "metadata": {},
   "source": [
    "#### Method to compute the average returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "148e6a2c-2431-4b89-ac1a-ceab7f7fcc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial return avg:  23.4\n"
     ]
    }
   ],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "initial_avg = compute_avg_return(eval_env, random_policy, num_eval_episodes)\n",
    "print(\"Initial return avg: \",initial_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b4420-5d47-4db9-bac2-9499348bac70",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ed9d975-aafe-48b7-b4ad-81fa7ce57168",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "def collect_step(environment, policy):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    # Add trajectory to the replay buffer\n",
    "    replay_buffer.add_batch(traj)\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "    collect_step(train_env, random_policy)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations of\n",
    "# these. For more details see the drivers module.\n",
    "\n",
    "# Dataset generates trajectories with shape [BxTx...] where\n",
    "# T = n_step_update + 1.\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "    num_steps=n_step_update + 1).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2d999fa-68b5-4768-903a-8cbca71d7485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'action': TensorSpec(shape=(64, 3), dtype=tf.int64, name=None),\n",
       "  'discount': TensorSpec(shape=(64, 3), dtype=tf.float32, name=None),\n",
       "  'next_step_type': TensorSpec(shape=(64, 3), dtype=tf.int32, name=None),\n",
       "  'observation': TensorSpec(shape=(64, 3, 4), dtype=tf.float32, name=None),\n",
       "  'policy_info': (),\n",
       "  'reward': TensorSpec(shape=(64, 3), dtype=tf.float32, name=None),\n",
       "  'step_type': TensorSpec(shape=(64, 3), dtype=tf.int32, name=None)}),\n",
       " BufferInfo(ids=TensorSpec(shape=(64, 3), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(64,), dtype=tf.float32, name=None)))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca418aa-1e1b-4c3e-aa67-a6090a8b0702",
   "metadata": {},
   "source": [
    "#### Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7dce080-4688-4699-9213-35b0d5856e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 3.033783197402954\n",
      "step = 400: loss = 2.4397497177124023\n",
      "step = 600: loss = 2.207005023956299\n",
      "step = 800: loss = 1.773998737335205\n",
      "step = 1000: loss = 1.5341060161590576\n",
      "step = 1000: Average Return = 50.70\n",
      "step = 1200: loss = 1.4539989233016968\n",
      "step = 1400: loss = 1.9140024185180664\n",
      "step = 1600: loss = 1.4026364088058472\n",
      "step = 1800: loss = 1.4463140964508057\n",
      "step = 2000: loss = 1.1912596225738525\n",
      "step = 2000: Average Return = 55.40\n",
      "step = 2200: loss = 1.3010103702545166\n",
      "step = 2400: loss = 1.361764907836914\n",
      "step = 2600: loss = 1.3198384046554565\n",
      "step = 2800: loss = 1.1071730852127075\n",
      "step = 3000: loss = 1.199534296989441\n",
      "step = 3000: Average Return = 107.40\n",
      "step = 3200: loss = 1.030282735824585\n",
      "step = 3400: loss = 0.7129906415939331\n",
      "step = 3600: loss = 1.1632516384124756\n",
      "step = 3800: loss = 1.090057134628296\n",
      "step = 4000: loss = 0.821159839630127\n",
      "step = 4000: Average Return = 96.30\n",
      "step = 4200: loss = 0.8600460290908813\n",
      "step = 4400: loss = 0.8259472250938416\n",
      "step = 4600: loss = 0.8453611731529236\n",
      "step = 4800: loss = 0.9366441965103149\n",
      "step = 5000: loss = 0.7695770859718323\n",
      "step = 5000: Average Return = 134.30\n",
      "step = 5200: loss = 0.9036197066307068\n",
      "step = 5400: loss = 0.8330811262130737\n",
      "step = 5600: loss = 0.9228366613388062\n",
      "step = 5800: loss = 0.8104417324066162\n",
      "step = 6000: loss = 0.6428142786026001\n",
      "step = 6000: Average Return = 148.70\n",
      "step = 6200: loss = 0.5364683866500854\n",
      "step = 6400: loss = 0.7590157389640808\n",
      "step = 6600: loss = 0.6538785099983215\n",
      "step = 6800: loss = 0.6614946126937866\n",
      "step = 7000: loss = 0.6561059951782227\n",
      "step = 7000: Average Return = 161.00\n",
      "step = 7200: loss = 0.8279566764831543\n",
      "step = 7400: loss = 0.6755198240280151\n",
      "step = 7600: loss = 0.770639955997467\n",
      "step = 7800: loss = 0.9639291763305664\n",
      "step = 8000: loss = 0.5236986875534058\n",
      "step = 8000: Average Return = 150.90\n",
      "step = 8200: loss = 0.6964654326438904\n",
      "step = 8400: loss = 0.6335989236831665\n",
      "step = 8600: loss = 0.579214334487915\n",
      "step = 8800: loss = 0.6161519885063171\n",
      "step = 9000: loss = 0.5299991965293884\n",
      "step = 9000: Average Return = 176.80\n",
      "step = 9200: loss = 0.4863269329071045\n",
      "step = 9400: loss = 0.8654630184173584\n",
      "step = 9600: loss = 0.40949705243110657\n",
      "step = 9800: loss = 0.6080946326255798\n",
      "step = 10000: loss = 0.789797306060791\n",
      "step = 10000: Average Return = 162.60\n",
      "step = 10200: loss = 0.4247138500213623\n",
      "step = 10400: loss = 0.5734189748764038\n",
      "step = 10600: loss = 0.5828313827514648\n",
      "step = 10800: loss = 0.6745090484619141\n",
      "step = 11000: loss = 0.42396479845046997\n",
      "step = 11000: Average Return = 200.00\n",
      "step = 11200: loss = 0.5755707025527954\n",
      "step = 11400: loss = 0.6035213470458984\n",
      "step = 11600: loss = 0.6336983442306519\n",
      "step = 11800: loss = 0.6258811950683594\n",
      "step = 12000: loss = 0.6411610245704651\n",
      "step = 12000: Average Return = 178.60\n",
      "step = 12200: loss = 0.6767075061798096\n",
      "step = 12400: loss = 0.708818793296814\n",
      "step = 12600: loss = 0.5265927314758301\n",
      "step = 12800: loss = 0.7779004573822021\n",
      "step = 13000: loss = 0.41368481516838074\n",
      "step = 13000: Average Return = 192.00\n",
      "step = 13200: loss = 0.43133771419525146\n",
      "step = 13400: loss = 0.42000722885131836\n",
      "step = 13600: loss = 0.5180740356445312\n",
      "step = 13800: loss = 0.6243652105331421\n",
      "step = 14000: loss = 0.40569522976875305\n",
      "step = 14000: Average Return = 191.60\n",
      "step = 14200: loss = 0.5744434595108032\n",
      "step = 14400: loss = 0.463189959526062\n",
      "step = 14600: loss = 0.36901581287384033\n",
      "step = 14800: loss = 0.8923311233520508\n",
      "step = 15000: loss = 0.32791024446487427\n",
      "step = 15000: Average Return = 190.20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience)\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "        \n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1:.2f}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4bbb5-f6de-4212-b691-88922828e034",
   "metadata": {},
   "source": [
    "#### Plotting the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c946e6c-7380-4d23-9b16-273f0225ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5500000000000007, 200.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e18ba-5df8-4c88-b386-43b696d813ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9641108f-aac1-44ca-a1bc-fcf5de13f23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comapring the| \n",
      "Initial average\t:\t23.399999618530273 \n",
      "Final average\t:\t137.84375\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comapring the| \\nInitial average\\t:\\t{initial_avg} \\nFinal average\\t:\\t{np.mean(returns)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "openAIgym.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
