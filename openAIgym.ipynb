{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
    "outputId": "c4ab66d1-4a67-4b4a-ca3e-60f9cc7ee39b"
   },
   "outputs": [],
   "source": [
    "#!pip install gym\n",
    "#!pip install --user tf-agents\n",
    "#!pip install tensorflow\n",
    "#!pip install ray\n",
    "\n",
    "#!pip install stable_baselines3\n",
    "#!pip install pyglet\n",
    "\n",
    "#!pip install keras\n",
    "#!pip install tf-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3d184-2d25-45fe-a314-f469aa808321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
   "metadata": {
    "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
    "tags": []
   },
   "source": [
    "### Import gym library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77f7d7d8-c25f-4070-874f-ee08289d2f93",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e616f27-90b1-40ce-b026-07a0d917a115",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'CartPole-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b765f1-7360-4ddf-90ed-3cdb5f4cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c7c70-10c8-48e9-a5f7-56bcc01383ab",
   "metadata": {
    "id": "aa719112-e9f3-45f6-89dd-b7052aaf4895",
    "tags": []
   },
   "source": [
    "### Reset the enviornment to its initial state and return 4 values in array\n",
    "\n",
    "![Observation](obs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
    "outputId": "b6615ebc-3139-4fb7-8ba7-8ff540f55a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03146594,  0.04136642, -0.0028272 , -0.04354905], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b517004-07ff-4301-9dec-93f7d221588e",
   "metadata": {
    "id": "d40c5768-22dd-4b26-b6fb-c4d27d763862"
   },
   "source": [
    "### observation_space returns the information about the environment space\n",
    "    # Box data type i.e. for continous observation\n",
    "    # returned Box object represents\n",
    "    # Box([[lower range of obs], [upper range obs], (number of dimensions), data type])\n",
    "![](env.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
    "outputId": "34ab00ef-1cd0-4235-aa48-c7364a7e14c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca2086-b302-412b-bcb9-26702a49185a",
   "metadata": {
    "id": "9ee88143-17be-49fe-ac30-dc2d22a0b5bd",
    "tags": []
   },
   "source": [
    "### action_space returns the Discrete object\n",
    "### sequence of integers, reprents the actions\n",
    "\n",
    "![](action.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
    "outputId": "da4c472a-2c8a-45a2-d251-46f6d0823b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e",
   "metadata": {
    "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e"
   },
   "outputs": [],
   "source": [
    "#env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe0e49-586d-4151-a3be-f7d9759f5abb",
   "metadata": {
    "id": "b2d47695-e63e-4509-b452-013b1c6da223"
   },
   "source": [
    "### Here a simple demonstartion of pushing cart to one side\n",
    "### To run the cell below change cell's type from Raw to Code\n",
    "\n",
    "### To take an action we need step() function\n",
    "    # step function returns 4 parameters\n",
    "    # [[env state], reward, terminal state(bool),]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0a860f1-206f-4d7f-8ab7-aa1fc50bf311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "nZn0d4IB9TJs",
    "outputId": "497f9c3b-1ea0-42c9-f1d4-f567700bfb40",
    "tags": []
   },
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for step_index in range(10000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(\"Step {}:\".format(step_index))\n",
    "    print(\"action: {}\".format(action))\n",
    "    print(\"observation: {}\".format(observation))\n",
    "    print(\"reward: {}\".format(reward))\n",
    "    print(\"done: {}\".format(done))\n",
    "    print(\"info: {}\".format(info), end =\"\\n\\n\")\n",
    "    \n",
    "    # if termination state has been reached\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
   "metadata": {
    "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
    "tags": []
   },
   "source": [
    "### Importing the tensorflow environments\n",
    "    # they generate tensors\n",
    "    # and replay buffer can be used to train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb8453fe-03ed-4862-9d7b-ba9ebd796351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00134ea1-f9e7-4111-bfd8-bd50ed648eee",
   "metadata": {},
   "source": [
    "### Running a test for average score using random action over 100 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13982b7b-2fe2-40af-9367-d86b8a31aa41",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episodes: 100 num_steps: 2187\n",
      "avg_length 21.87 avg_reward: 21.87\n"
     ]
    }
   ],
   "source": [
    "env = suite_gym.load(ENV_NAME)\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 100\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not time_step.is_last():\n",
    "        action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "        #print(action)\n",
    "        time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        episode_reward += time_step.reward.numpy()\n",
    "    rewards.append(episode_reward)\n",
    "    steps.append(episode_steps)\n",
    "    time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa727e9e-5d0d-40a6-bf70-e342c028e46e",
   "metadata": {},
   "source": [
    "### Importing Q Policy libraries\n",
    "    # Agents trained will be based on Deep Q-Learning network (DQN)\n",
    "    # Q is quality of given moves\n",
    "    # It Predicts Q value for each discrete action Q: State * Action --> Reward.\n",
    "![](bellman.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8168b328-1451-492b-8bc0-94eb8faa19b5",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8"
   },
   "outputs": [],
   "source": [
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import network\n",
    "from tf_agents.policies import q_policy\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9faf7ae0-71aa-4db0-bc17-4f5a118daf07",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [],
   "source": [
    "input_tensor_spec = tensor_spec.TensorSpec((4,), tf.float32)\n",
    "time_step_spec = ts.time_step_spec(input_tensor_spec)\n",
    "action_spec = tensor_spec.BoundedTensorSpec((),\n",
    "                                            tf.int32,\n",
    "                                            minimum=0,\n",
    "                                            maximum=1)\n",
    "\n",
    "num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "#print(action_spec, num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d4f99fc4-f9e5-4bd5-a8cb-42d466e6d95c",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int32)\n",
      "Action distribution:\n",
      "tfp.distributions.Categorical(\"Categorical\", batch_shape=[2], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "class QNetwork(network.Network):\n",
    "\n",
    "    def __init__(self, input_tensor_spec, action_spec, num_actions=num_actions, name=None):\n",
    "        super(QNetwork, self).__init__(\n",
    "            input_tensor_spec=input_tensor_spec,\n",
    "            state_spec=(),\n",
    "            name=name)\n",
    "        self._sub_layers = [\n",
    "            tf.keras.layers.Dense(num_actions),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, step_type=None, network_state=()):\n",
    "        del step_type\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        for layer in self._sub_layers:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs, network_state\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "observation = tf.ones([batch_size] + time_step_spec.observation.shape.as_list())\n",
    "time_steps = ts.restart(observation, batch_size=batch_size)\n",
    "\n",
    "my_q_network = QNetwork(\n",
    "    input_tensor_spec=input_tensor_spec,\n",
    "    action_spec=action_spec)\n",
    "\n",
    "my_q_policy = q_policy.QPolicy(\n",
    "    time_step_spec, action_spec, q_network=my_q_network)\n",
    "\n",
    "action_step = my_q_policy.action(time_steps)\n",
    "distribution_step = my_q_policy.distribution(time_steps)\n",
    "\n",
    "print('Action:')\n",
    "print(action_step.action)\n",
    "\n",
    "print('Action distribution:')\n",
    "print(distribution_step.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b65d6-6e11-4280-b836-585d0e2fb079",
   "metadata": {
    "id": "8e1b65d6-6e11-4280-b836-585d0e2fb079"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
    "outputId": "03bb33c1-65f9-4f09-917e-6a72e61b6442"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IAYGWxX3E8-n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "IAYGWxX3E8-n",
    "outputId": "294924fc-0db9-4e90-85f2-11e18c8885fb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "openAIgym.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
