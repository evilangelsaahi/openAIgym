{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
    "outputId": "c4ab66d1-4a67-4b4a-ca3e-60f9cc7ee39b"
   },
   "outputs": [],
   "source": [
    "#!pip install gym\n",
    "#!pip install tensorflow\n",
    "#!pip install pyglet\n",
    "#!pip install keras\n",
    "#!pip install tf-agents\n",
    "\n",
    "#!pip install reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f16e2b39-7162-403c-8197-3f26609e4d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
   "metadata": {
    "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
    "tags": []
   },
   "source": [
    "### Import gym library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77f7d7d8-c25f-4070-874f-ee08289d2f93",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e616f27-90b1-40ce-b026-07a0d917a115",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7b765f1-7360-4ddf-90ed-3cdb5f4cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c7c70-10c8-48e9-a5f7-56bcc01383ab",
   "metadata": {
    "id": "aa719112-e9f3-45f6-89dd-b7052aaf4895",
    "tags": []
   },
   "source": [
    "### Reset the enviornment to its initial state and return 4 values in array\n",
    "\n",
    "![Observation](obs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
    "outputId": "b6615ebc-3139-4fb7-8ba7-8ff540f55a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0429323 , -0.01812948, -0.01866479, -0.04680137], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b517004-07ff-4301-9dec-93f7d221588e",
   "metadata": {
    "id": "d40c5768-22dd-4b26-b6fb-c4d27d763862"
   },
   "source": [
    "### observation_space returns the information about the environment space\n",
    "    # Box data type i.e. for continous observation\n",
    "    # returned Box object represents\n",
    "    # Box([[lower range of obs], [upper range obs], (number of dimensions), data type])\n",
    "![](env.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
    "outputId": "34ab00ef-1cd0-4235-aa48-c7364a7e14c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca2086-b302-412b-bcb9-26702a49185a",
   "metadata": {
    "id": "9ee88143-17be-49fe-ac30-dc2d22a0b5bd",
    "tags": []
   },
   "source": [
    "### action_space returns the Discrete object\n",
    "### sequence of integers, reprents the actions\n",
    "\n",
    "![](action.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
    "outputId": "da4c472a-2c8a-45a2-d251-46f6d0823b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e",
   "metadata": {
    "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e"
   },
   "outputs": [],
   "source": [
    "#env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e347e-c2b3-4f36-8593-0dc799869671",
   "metadata": {
    "id": "b2d47695-e63e-4509-b452-013b1c6da223",
    "tags": []
   },
   "source": [
    "### Termination state is reached when one of these conditions are met\n",
    "### and done parameter is set to True\n",
    "\n",
    "![](eps.png)\n",
    "\n",
    "### Here a simple demonstartion of pushing cart to one side\n",
    "### To run the cell below change cell's type from Raw to Code\n",
    "\n",
    "### To take an action we need step() function\n",
    "    # step function returns 4 parameters\n",
    "    # [[obs state], reward, terminal state(done = bool),info]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff0ddb04-12fb-4b6a-b758-8dba64dfbe68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "nZn0d4IB9TJs",
    "outputId": "497f9c3b-1ea0-42c9-f1d4-f567700bfb40",
    "tags": []
   },
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for step_index in range(10000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(\"Step {}:\".format(step_index))\n",
    "    print(\"action: {}\".format(action))\n",
    "    print(\"observation: {}\".format(observation))\n",
    "    print(\"reward: {}\".format(reward))\n",
    "    print(\"done: {}\".format(done))\n",
    "    print(\"info: {}\".format(info), end =\"\\n\\n\")\n",
    "    \n",
    "    # if termination state has been reached\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
   "metadata": {
    "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
    "tags": []
   },
   "source": [
    "### Importing the tensorflow environments\n",
    "    # they generate tensors\n",
    "    # and replay buffer can be used to train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb8453fe-03ed-4862-9d7b-ba9ebd796351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00134ea1-f9e7-4111-bfd8-bd50ed648eee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running a test for average score using random action over 100 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13982b7b-2fe2-40af-9367-d86b8a31aa41",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episodes: 100 num_steps: 2197\n",
      "avg_length 21.97 avg_reward: 21.97\n"
     ]
    }
   ],
   "source": [
    "env = suite_gym.load(env_name)\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 100\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not time_step.is_last():\n",
    "        action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "        #print(action)\n",
    "        time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        episode_reward += time_step.reward.numpy()\n",
    "    rewards.append(episode_reward)\n",
    "    steps.append(episode_steps)\n",
    "    time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa727e9e-5d0d-40a6-bf70-e342c028e46e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing Q Policy libraries\n",
    "    # Agents trained will be based on Deep Q-Learning network (DQN)\n",
    "    # Q is quality of given moves\n",
    "    # It Predicts Q value for each discrete action Q: State * Action --> Reward.\n",
    "    # Bellman equation is a detailed explanation of this algorithm\n",
    "![](bellman.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8168b328-1451-492b-8bc0-94eb8faa19b5",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8"
   },
   "outputs": [],
   "source": [
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import network\n",
    "from tf_agents.policies import q_policy\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9faf7ae0-71aa-4db0-bc17-4f5a118daf07",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)) \n",
      "\n",
      " Number of actions: \t 2\n"
     ]
    }
   ],
   "source": [
    "input_tensor_spec = tensor_spec.TensorSpec((4,), tf.float32)\n",
    "time_step_spec = ts.time_step_spec(input_tensor_spec)\n",
    "action_spec = tensor_spec.BoundedTensorSpec((),\n",
    "                                            tf.int32,\n",
    "                                            minimum=0,\n",
    "                                            maximum=1)\n",
    "\n",
    "num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(action_spec, \"\\n\\n Number of actions: \\t\", num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4f99fc4-f9e5-4bd5-a8cb-42d466e6d95c",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "Action distribution:\n",
      "tfp.distributions.Categorical(\"Categorical\", batch_shape=[2], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "class QNetwork(network.Network):\n",
    "\n",
    "    def __init__(self, input_tensor_spec, action_spec, num_actions=num_actions, name=None):\n",
    "        super(QNetwork, self).__init__(\n",
    "            input_tensor_spec=input_tensor_spec,\n",
    "            state_spec=(),\n",
    "            name=name)\n",
    "        self._sub_layers = [\n",
    "            tf.keras.layers.Dense(num_actions),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, step_type=None, network_state=()):\n",
    "        del step_type\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        for layer in self._sub_layers:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs, network_state\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "observation = tf.ones([batch_size] + time_step_spec.observation.shape.as_list())\n",
    "time_steps = ts.restart(observation, batch_size=batch_size)\n",
    "\n",
    "my_q_network = QNetwork(\n",
    "    input_tensor_spec=input_tensor_spec,\n",
    "    action_spec=action_spec)\n",
    "\n",
    "my_q_policy = q_policy.QPolicy(\n",
    "    time_step_spec, action_spec, q_network=my_q_network)\n",
    "\n",
    "action_step = my_q_policy.action(time_steps)\n",
    "distribution_step = my_q_policy.distribution(time_steps)\n",
    "\n",
    "print('Action:')\n",
    "print(action_step.action)\n",
    "\n",
    "print('Action distribution:')\n",
    "print(distribution_step.action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d05597-9901-4e46-93dd-2ccedd1b3b27",
   "metadata": {
    "id": "8e1b65d6-6e11-4280-b836-585d0e2fb079"
   },
   "source": [
    "### Importing TensorFlow Drivers\n",
    "    # There are 2 types of drivers\n",
    "    # DynamicStepDriver, which terminates after a given number of (valid) environment steps\n",
    "    # DynamicEpisodeDriver, which terminates after a given number of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8c20b12-4145-40f0-9b15-7bef11231116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.drivers import dynamic_episode_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
    "outputId": "03bb33c1-65f9-4f09-917e-6a72e61b6442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_time_step TimeStep(\n",
      "{'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
      " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
      "array([[-0.00905133, -0.00811464, -0.00313077,  0.01084824]],\n",
      "      dtype=float32)>,\n",
      " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>})\n",
      "Number of Steps:  4709\n",
      "Number of Episodes:  100\n",
      "policy_state ()\n"
     ]
    }
   ],
   "source": [
    "num_episodes = tf_metrics.NumberOfEpisodes()\n",
    "env_steps = tf_metrics.EnvironmentSteps()\n",
    "observers = [num_episodes, env_steps]\n",
    "\n",
    "driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    tf_env, my_q_policy, observers, num_episodes=100)\n",
    "\n",
    "# Initial driver.run will reset the environment and initialize the policy.\n",
    "final_time_step, policy_state = driver.run()\n",
    "\n",
    "print('final_time_step', final_time_step)\n",
    "print('Number of Steps: ', env_steps.result().numpy())\n",
    "print('Number of Episodes: ', num_episodes.result().numpy())\n",
    "print('policy_state', policy_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f1c96-4304-44ea-98f6-ed2ade524186",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "IAYGWxX3E8-n",
    "outputId": "294924fc-0db9-4e90-85f2-11e18c8885fb",
    "tags": []
   },
   "source": [
    "### Importing Replay Buffers\n",
    "    # replay buffers are used to store trajectories of experience when executing a policy in an environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d910dae7-45a6-4a2b-89fa-2711f377e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks import q_network\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b75b466-089d-4c3c-84cf-b1782ac11c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_net = q_network.QNetwork(\n",
    "    tf_env.time_step_spec().observation,\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=(100,))\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(0.001))\n",
    "\n",
    "replay_buffer_capacity = 1000\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "# Add an observer that adds to the replay buffer:\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "collect_steps_per_iteration = 10\n",
    "collect_op = dynamic_step_driver.DynamicStepDriver(\n",
    "  tf_env,\n",
    "  agent.collect_policy,\n",
    "  observers=replay_observer,\n",
    "  num_steps=collect_steps_per_iteration).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b38c71a-1d1c-4c75-9625-e41963e62d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[ 0.03602472,  0.36235705, -0.03630416, -0.62500376]],\n",
       "       dtype=float32)>,\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8428cbb-fdd4-4048-8379-d963aabf9fbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Above all cells where the basic idea of building a network and training an agent\n",
    "## Now we proceed by putting all together the knowledge from tensorflow documentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8cca5-bf2c-4eb2-953b-24b7b1e66357",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing libraries for training the DQN C51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33fee400-5ce1-4ae2-afe8-3f9b5ad0eb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import categorical_q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00059a4-1019-4c85-81db-ff1192ceb3c2",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecda9124-69b6-42e7-a4e9-4db992279094",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\" # @param {type:\"string\"}\n",
    "num_iterations = 15000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "gamma = 0.99\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_atoms = 51  # @param {type:\"integer\"}\n",
    "min_q_value = -20  # @param {type:\"integer\"}\n",
    "max_q_value = 20  # @param {type:\"integer\"}\n",
    "n_step_update = 2  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69493925-55d0-4753-985e-a3f7ff80b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87481546-0469-47c4-a250-f3576c246509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([-0.03795713,  0.03568176, -0.02366152, -0.00662412], dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "#PIL.Image.fromarray(env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01648881-a593-4ab0-b39a-8fa3a1bd19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9c97e90-be53-4cc0-b4e5-640e7f3e60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d2c4718-599d-4b39-81ef-7a6503d388b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a68af7d-a997-4aa5-bbcb-ed531a1a9e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4a06707-9c14-402b-b488-c3f18e73ae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.00303674,  0.01947403, -0.00965656, -0.03936318], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.00342622,  0.21473311, -0.01044383, -0.33507714], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:',)\n",
    "print(time_step, end=\"\\n\\n\")\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb90c9c9-7e85-4271-bec0-b789f945250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdfe4de6-b1c9-4425-a564-ab07f350cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_q_net = categorical_q_network.CategoricalQNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    num_atoms=num_atoms,\n",
    "    fc_layer_params=fc_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5f8be9c-78d3-44ca-ad6f-4f02a141d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = categorical_dqn_agent.CategoricalDqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    categorical_q_network=categorical_q_net,\n",
    "    optimizer=optimizer,\n",
    "    min_q_value=min_q_value,\n",
    "    max_q_value=max_q_value,\n",
    "    n_step_update=n_step_update,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    gamma=gamma,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b38e1f-df96-46ae-9d7d-f00ece02da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "148e6a2c-2431-4b89-ac1a-ceab7f7fcc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b4420-5d47-4db9-bac2-9499348bac70",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ed9d975-aafe-48b7-b4ad-81fa7ce57168",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "def collect_step(environment, policy):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    # Add trajectory to the replay buffer\n",
    "    replay_buffer.add_batch(traj)\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "    collect_step(train_env, random_policy)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations of\n",
    "# these. For more details see the drivers module.\n",
    "\n",
    "# Dataset generates trajectories with shape [BxTx...] where\n",
    "# T = n_step_update + 1.\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "    num_steps=n_step_update + 1).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2d999fa-68b5-4768-903a-8cbca71d7485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'action': TensorSpec(shape=(64, 3), dtype=tf.int64, name=None),\n",
       "  'discount': TensorSpec(shape=(64, 3), dtype=tf.float32, name=None),\n",
       "  'next_step_type': TensorSpec(shape=(64, 3), dtype=tf.int32, name=None),\n",
       "  'observation': TensorSpec(shape=(64, 3, 4), dtype=tf.float32, name=None),\n",
       "  'policy_info': (),\n",
       "  'reward': TensorSpec(shape=(64, 3), dtype=tf.float32, name=None),\n",
       "  'step_type': TensorSpec(shape=(64, 3), dtype=tf.int32, name=None)}),\n",
       " BufferInfo(ids=TensorSpec(shape=(64, 3), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(64,), dtype=tf.float32, name=None)))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7dce080-4688-4699-9213-35b0d5856e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sahilbohot/miniforge3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "step = 200: loss = 3.2562124729156494\n",
      "step = 400: loss = 2.553927421569824\n",
      "step = 600: loss = 2.3349146842956543\n",
      "step = 800: loss = 2.30843448638916\n",
      "step = 1000: loss = 1.977351427078247\n",
      "step = 1000: Average Return = 80.00\n",
      "step = 1200: loss = 1.837301254272461\n",
      "step = 1400: loss = 1.6567916870117188\n",
      "step = 1600: loss = 1.8029894828796387\n",
      "step = 1800: loss = 1.536992073059082\n",
      "step = 2000: loss = 1.44024658203125\n",
      "step = 2000: Average Return = 177.90\n",
      "step = 2200: loss = 1.1200989484786987\n",
      "step = 2400: loss = 1.3407312631607056\n",
      "step = 2600: loss = 0.9893100261688232\n",
      "step = 2800: loss = 1.129988670349121\n",
      "step = 3000: loss = 0.9153160452842712\n",
      "step = 3000: Average Return = 117.10\n",
      "step = 3200: loss = 1.021146535873413\n",
      "step = 3400: loss = 0.9993302822113037\n",
      "step = 3600: loss = 0.9544727802276611\n",
      "step = 3800: loss = 0.8907978534698486\n",
      "step = 4000: loss = 1.071180820465088\n",
      "step = 4000: Average Return = 135.30\n",
      "step = 4200: loss = 0.8761440515518188\n",
      "step = 4400: loss = 0.9891133308410645\n",
      "step = 4600: loss = 0.685125470161438\n",
      "step = 4800: loss = 0.8006587624549866\n",
      "step = 5000: loss = 0.88251793384552\n",
      "step = 5000: Average Return = 122.20\n",
      "step = 5200: loss = 0.767084538936615\n",
      "step = 5400: loss = 0.7136589288711548\n",
      "step = 5600: loss = 0.7415536642074585\n",
      "step = 5800: loss = 0.7450517416000366\n",
      "step = 6000: loss = 0.8848978877067566\n",
      "step = 6000: Average Return = 182.20\n",
      "step = 6200: loss = 0.7660223245620728\n",
      "step = 6400: loss = 0.7775859832763672\n",
      "step = 6600: loss = 0.7662304639816284\n",
      "step = 6800: loss = 0.786474347114563\n",
      "step = 7000: loss = 0.9066590666770935\n",
      "step = 7000: Average Return = 189.70\n",
      "step = 7200: loss = 0.5163321495056152\n",
      "step = 7400: loss = 0.6714386940002441\n",
      "step = 7600: loss = 0.5849819183349609\n",
      "step = 7800: loss = 0.6470351219177246\n",
      "step = 8000: loss = 0.6408251523971558\n",
      "step = 8000: Average Return = 190.90\n",
      "step = 8200: loss = 0.8783410787582397\n",
      "step = 8400: loss = 0.39626437425613403\n",
      "step = 8600: loss = 0.5807170867919922\n",
      "step = 8800: loss = 0.5559418201446533\n",
      "step = 9000: loss = 0.6432565450668335\n",
      "step = 9000: Average Return = 188.30\n",
      "step = 9200: loss = 0.6879700422286987\n",
      "step = 9400: loss = 0.6059513092041016\n",
      "step = 9600: loss = 0.6694365739822388\n",
      "step = 9800: loss = 0.7587978839874268\n",
      "step = 10000: loss = 0.4587748050689697\n",
      "step = 10000: Average Return = 197.10\n",
      "step = 10200: loss = 0.7077890634536743\n",
      "step = 10400: loss = 0.5502736568450928\n",
      "step = 10600: loss = 0.5665357708930969\n",
      "step = 10800: loss = 0.395842581987381\n",
      "step = 11000: loss = 0.3555026054382324\n",
      "step = 11000: Average Return = 190.20\n",
      "step = 11200: loss = 0.4937620759010315\n",
      "step = 11400: loss = 0.5776912569999695\n",
      "step = 11600: loss = 0.5372791290283203\n",
      "step = 11800: loss = 0.5489360094070435\n",
      "step = 12000: loss = 0.7617581486701965\n",
      "step = 12000: Average Return = 177.40\n",
      "step = 12200: loss = 0.5364133715629578\n",
      "step = 12400: loss = 0.5865058898925781\n",
      "step = 12600: loss = 0.5736383199691772\n",
      "step = 12800: loss = 0.7123908996582031\n",
      "step = 13000: loss = 0.6277920007705688\n",
      "step = 13000: Average Return = 162.60\n",
      "step = 13200: loss = 0.7748562097549438\n",
      "step = 13400: loss = 0.6177600622177124\n",
      "step = 13600: loss = 0.6939457654953003\n",
      "step = 13800: loss = 0.5410245656967163\n",
      "step = 14000: loss = 0.3763568103313446\n",
      "step = 14000: Average Return = 183.20\n",
      "step = 14200: loss = 0.5247446298599243\n",
      "step = 14400: loss = 0.7378223538398743\n",
      "step = 14600: loss = 0.6110137104988098\n",
      "step = 14800: loss = 0.5722367763519287\n",
      "step = 15000: loss = 0.2952133119106293\n",
      "step = 15000: Average Return = 195.90\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience)\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1:.2f}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c68ae-bd2d-42df-9d90-a5183e33c390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c946e6c-7380-4d23-9b16-273f0225ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.510000896453857, 200.0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=200)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "openAIgym.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
