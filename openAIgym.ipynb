{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evilangelsaahi/openAIgym/blob/main/openAIgym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
      "metadata": {
        "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca"
      },
      "outputs": [],
      "source": [
        "#!pip install gym\n",
        "#!pip install --user tf-agents\n",
        "#!pip install tensorflow\n",
        "#!pip install ray\n",
        "#!pip install stable_baselines3\n",
        "#!pip install pyglet\n",
        "#!pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
      "metadata": {
        "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
        "tags": []
      },
      "source": [
        "### Import gym library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7736aed5-f7b7-4495-be9e-55c85a818c72",
      "metadata": {
        "id": "7736aed5-f7b7-4495-be9e-55c85a818c72"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6f42e8-b5c6-42ad-8a6d-354192fae35d",
      "metadata": {
        "id": "ee6f42e8-b5c6-42ad-8a6d-354192fae35d"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29add3e5-ef15-4033-9e74-d66756b3ef21",
      "metadata": {
        "id": "29add3e5-ef15-4033-9e74-d66756b3ef21"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3ac6aa8-663b-4c14-834b-b4ec6bc872c6",
      "metadata": {
        "id": "a3ac6aa8-663b-4c14-834b-b4ec6bc872c6"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b980b70b-a0ee-4f0a-921c-4661cf751dc9",
      "metadata": {
        "id": "b980b70b-a0ee-4f0a-921c-4661cf751dc9"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc587ab7-aad8-48b1-9b43-bad1e4053bb5",
      "metadata": {
        "id": "bc587ab7-aad8-48b1-9b43-bad1e4053bb5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
      "metadata": {
        "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308"
      },
      "outputs": [],
      "source": [
        "env_name = 'CartPole-v0'\n",
        "env = gym.make(env_name)\n",
        "env.reset()\n",
        "goal_steps = 200\n",
        "score_requirement = 195\n",
        "intial_games = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa719112-e9f3-45f6-89dd-b7052aaf4895",
      "metadata": {
        "id": "aa719112-e9f3-45f6-89dd-b7052aaf4895"
      },
      "source": [
        "### set the enviornment to its initial state and return 4 values in array\n",
        "![Screen Shot 2022-06-10 at 3.42.13 PM.png](attachment:654c6303-9013-4f0c-ae2c-6c5751de37cd.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
      "metadata": {
        "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89"
      },
      "outputs": [],
      "source": [
        "obs = env.reset()\n",
        "obs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d40c5768-22dd-4b26-b6fb-c4d27d763862",
      "metadata": {
        "id": "d40c5768-22dd-4b26-b6fb-c4d27d763862"
      },
      "source": [
        "### observation_space returns the information about the environment space\n",
        "    # Box data type i.e. for continous observation\n",
        "    # returned Box object represents\n",
        "    # Box([[lower range of obs], [upper range obs], (number of dimensions), data type])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
      "metadata": {
        "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d"
      },
      "outputs": [],
      "source": [
        "env.observation_space"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ee88143-17be-49fe-ac30-dc2d22a0b5bd",
      "metadata": {
        "id": "9ee88143-17be-49fe-ac30-dc2d22a0b5bd",
        "tags": []
      },
      "source": [
        "### action_space returns the Discrete object \n",
        "### sequence of integers, reprents the actions\n",
        "![Screen Shot 2022-06-10 at 3.45.03 PM.png](attachment:1bfb2d6b-c3cf-4723-8b37-9fd8dde1e890.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
      "metadata": {
        "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10"
      },
      "outputs": [],
      "source": [
        "env.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e",
      "metadata": {
        "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e"
      },
      "outputs": [],
      "source": [
        "#env.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d47695-e63e-4509-b452-013b1c6da223",
      "metadata": {
        "id": "b2d47695-e63e-4509-b452-013b1c6da223"
      },
      "source": [
        "### To take an action we need step() function\n",
        "    # step function returns 4 parameters\n",
        "    # [[env state], reward, terminal state(bool),]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f33b687e-0f5e-4bff-aef2-1b104734e3d0",
      "metadata": {
        "id": "f33b687e-0f5e-4bff-aef2-1b104734e3d0"
      },
      "outputs": [],
      "source": [
        "#env.step(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91d81d72-0171-4b3d-b6be-c2e18c65ef2d",
      "metadata": {
        "id": "91d81d72-0171-4b3d-b6be-c2e18c65ef2d"
      },
      "outputs": [],
      "source": [
        "#steps, reward, done, _ = env.step(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a565f4b9-6531-49a2-8a63-082206401c04",
      "metadata": {
        "id": "a565f4b9-6531-49a2-8a63-082206401c04",
        "tags": []
      },
      "source": [
        "### Below 2 blocks are a simple demonstartion of pushing cart to one side"
      ]
    },
    {
      "cell_type": "raw",
      "id": "764aa8b7-23d9-4682-ba6b-2aa12b12cb9a",
      "metadata": {
        "id": "764aa8b7-23d9-4682-ba6b-2aa12b12cb9a"
      },
      "source": [
        "obs = env.reset()\n",
        "for eps in range(5):\n",
        "    obs = env.reset()\n",
        "    while True:\n",
        "        print(f\"Pole angle: {np.degrees(obs[2]) : .3f}\", end=\" \")\n",
        "        obs, reward, done,_ = env.step(1)\n",
        "        print(f\"Reward:{reward}\", end = \" \")\n",
        "        print(f\"Terminal state reached: {done}\")\n",
        "        if done:\n",
        "            break\n",
        "        env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbe7ed11-a2d2-4b26-a4cd-050913729a38",
      "metadata": {
        "id": "cbe7ed11-a2d2-4b26-a4cd-050913729a38"
      },
      "outputs": [],
      "source": [
        "for episode in range(1, 11):\n",
        "    score = 0\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "      env.render()\n",
        "      action = env.action_space.sample()\n",
        "      n_state, reward, done, info = env.step(action)\n",
        "      score += reward\n",
        "      \n",
        "    print('Episode:', episode, 'Score:', score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7bbe803-e638-4b6c-9704-f0d1926b638d",
      "metadata": {
        "id": "f7bbe803-e638-4b6c-9704-f0d1926b638d"
      },
      "outputs": [],
      "source": [
        "# to close the window uncomment the command below\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nZn0d4IB9TJs",
      "metadata": {
        "id": "nZn0d4IB9TJs"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "env = gym.make('CartPole-v0')\n",
        "env.reset()\n",
        "for step_index in range(1000):\n",
        "    env.render()\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    print(\"Step {}:\".format(step_index))\n",
        "    print(\"action: {}\".format(action))\n",
        "    print(\"observation: {}\".format(observation))\n",
        "    print(\"reward: {}\".format(reward))\n",
        "    print(\"done: {}\".format(done))\n",
        "    print(\"info: {}\".format(info))\n",
        "    if done:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
      "metadata": {
        "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e"
      },
      "source": [
        "### Training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8",
      "metadata": {
        "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8"
      },
      "outputs": [],
      "source": [
        "def model_data_preparation():\n",
        "    training_data = []\n",
        "    accepted_scores = []\n",
        "    for game_index in range(intial_games):\n",
        "        score = 0\n",
        "        game_memory = []\n",
        "        previous_observation = []\n",
        "        for step_index in range(goal_steps):\n",
        "            action = random.randrange(0, 2)\n",
        "            observation, reward, done, info = env.step(action)\n",
        "            \n",
        "            if len(previous_observation) > 0:\n",
        "                game_memory.append([previous_observation, action])\n",
        "                \n",
        "            previous_observation = observation\n",
        "            score += reward\n",
        "            if done:\n",
        "                break\n",
        "            \n",
        "        if score >= score_requirement:\n",
        "            accepted_scores.append(score)\n",
        "            for data in game_memory:\n",
        "                if data[1] == 1:\n",
        "                    output = [0, 1]\n",
        "                elif data[1] == 0:\n",
        "                    output = [1, 0]\n",
        "                training_data.append([data[0], output])\n",
        "        \n",
        "        env.reset()\n",
        "\n",
        "    print(accepted_scores)\n",
        "    \n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c6f170e-e4c4-42c8-9add-0ccc13fd11fd",
      "metadata": {
        "id": "5c6f170e-e4c4-42c8-9add-0ccc13fd11fd"
      },
      "source": [
        "### Building and model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55b5075-2f22-459c-9d9c-fa34091387bb",
      "metadata": {
        "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
      },
      "outputs": [],
      "source": [
        "def build_model(input_size, output_size):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_size, activation='relu'))\n",
        "    model.add(Dense(52, activation='relu'))\n",
        "    model.add(Dense(output_size, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=Adam())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e1b65d6-6e11-4280-b836-585d0e2fb079",
      "metadata": {
        "id": "8e1b65d6-6e11-4280-b836-585d0e2fb079"
      },
      "outputs": [],
      "source": [
        "def train_model(training_data):\n",
        "    X = np.array([i[0] for i in training_data]).reshape(-1, len(training_data[0][0]))\n",
        "    y = np.array([i[1] for i in training_data]).reshape(-1, len(training_data[0][1]))\n",
        "    model = build_model(input_size=len(X[0]), output_size=len(y[0]))\n",
        "    \n",
        "    model.fit(X, y, epochs=10)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
      "metadata": {
        "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c"
      },
      "outputs": [],
      "source": [
        "training_data = model_data_preparation()\n",
        "trained_model = train_model(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IAYGWxX3E8-n",
      "metadata": {
        "id": "IAYGWxX3E8-n"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "choices = []\n",
        "for each_game in range(100):\n",
        "    score = 0\n",
        "    prev_obs = []\n",
        "    for step_index in range(goal_steps):\n",
        "      #env.render()\n",
        "      if len(prev_obs)==0:\n",
        "            action = random.randrange(0,2)\n",
        "      else:\n",
        "            action = np.argmax(trained_model.predict(prev_obs.reshape(-1, len(prev_obs)))[0])\n",
        "        \n",
        "      choices.append(action)\n",
        "      new_observation, reward, done, info = env.step(action)\n",
        "      prev_obs = new_observation\n",
        "      score+=reward\n",
        "      if done:\n",
        "          break\n",
        "\n",
        "    env.reset()\n",
        "    scores.append(score)\n",
        "\n",
        "print(scores)\n",
        "print('Average Score:', sum(scores)/len(scores))\n",
        "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "openAIgym.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}