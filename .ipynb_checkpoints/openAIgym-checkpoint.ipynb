{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9c603ac-7651-4ecd-bb53-b5abca4005ca",
    "outputId": "c4ab66d1-4a67-4b4a-ca3e-60f9cc7ee39b"
   },
   "outputs": [],
   "source": [
    "#!pip install gym\n",
    "#!pip install tensorflow\n",
    "#!pip install pyglet\n",
    "#!pip install keras\n",
    "#!pip install tf-agents\n",
    "\n",
    "#!pip install reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f16e2b39-7162-403c-8197-3f26609e4d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
   "metadata": {
    "id": "5d81c2e8-998e-45b3-b228-d0d194447ddf",
    "tags": []
   },
   "source": [
    "### Import gym library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77f7d7d8-c25f-4070-874f-ee08289d2f93",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e616f27-90b1-40ce-b026-07a0d917a115",
   "metadata": {
    "id": "15cf06cb-4f6e-4d25-b46a-7df5deaac308",
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7b765f1-7360-4ddf-90ed-3cdb5f4cca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c7c70-10c8-48e9-a5f7-56bcc01383ab",
   "metadata": {
    "id": "aa719112-e9f3-45f6-89dd-b7052aaf4895",
    "tags": []
   },
   "source": [
    "### Reset the enviornment to its initial state and return 4 values in array\n",
    "\n",
    "![Observation](obs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bad1e86-4bdf-4ba3-9dfe-4fe0734a0a89",
    "outputId": "b6615ebc-3139-4fb7-8ba7-8ff540f55a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00762122, -0.02096623,  0.00330917, -0.04233976], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b517004-07ff-4301-9dec-93f7d221588e",
   "metadata": {
    "id": "d40c5768-22dd-4b26-b6fb-c4d27d763862"
   },
   "source": [
    "### observation_space returns the information about the environment space\n",
    "    # Box data type i.e. for continous observation\n",
    "    # returned Box object represents\n",
    "    # Box([[lower range of obs], [upper range obs], (number of dimensions), data type])\n",
    "![](env.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb59344-f5f1-4c63-9dfb-e256f5c4735d",
    "outputId": "34ab00ef-1cd0-4235-aa48-c7364a7e14c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca2086-b302-412b-bcb9-26702a49185a",
   "metadata": {
    "id": "9ee88143-17be-49fe-ac30-dc2d22a0b5bd",
    "tags": []
   },
   "source": [
    "### action_space returns the Discrete object\n",
    "### sequence of integers, reprents the actions\n",
    "\n",
    "![](action.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96af11dc-cfdd-4e2d-b34c-ce08b3e92e10",
    "outputId": "da4c472a-2c8a-45a2-d251-46f6d0823b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e",
   "metadata": {
    "id": "a28f61ad-f1c5-4c84-b558-c476bd31005e"
   },
   "outputs": [],
   "source": [
    "#env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e347e-c2b3-4f36-8593-0dc799869671",
   "metadata": {
    "id": "b2d47695-e63e-4509-b452-013b1c6da223",
    "tags": []
   },
   "source": [
    "### Termination state is reached when one of these conditions are met\n",
    "### and done parameter is set to True\n",
    "\n",
    "![](eps.png)\n",
    "\n",
    "### Here a simple demonstartion of pushing cart to one side\n",
    "### To run the cell below change cell's type from Raw to Code\n",
    "\n",
    "### To take an action we need step() function\n",
    "    # step function returns 4 parameters\n",
    "    # [[obs state], reward, terminal state(done = bool),info]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff0ddb04-12fb-4b6a-b758-8dba64dfbe68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "nZn0d4IB9TJs",
    "outputId": "497f9c3b-1ea0-42c9-f1d4-f567700bfb40",
    "tags": []
   },
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for step_index in range(10000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(\"Step {}:\".format(step_index))\n",
    "    print(\"action: {}\".format(action))\n",
    "    print(\"observation: {}\".format(observation))\n",
    "    print(\"reward: {}\".format(reward))\n",
    "    print(\"done: {}\".format(done))\n",
    "    print(\"info: {}\".format(info), end =\"\\n\\n\")\n",
    "    \n",
    "    # if termination state has been reached\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
   "metadata": {
    "id": "b145d0c1-7c38-4bb9-b48a-3572c835c00e",
    "tags": []
   },
   "source": [
    "### Importing the tensorflow environments\n",
    "    # they generate tensors\n",
    "    # and replay buffer can be used to train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb8453fe-03ed-4862-9d7b-ba9ebd796351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import suite_gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00134ea1-f9e7-4111-bfd8-bd50ed648eee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running a test for average score using random actions over 100 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13982b7b-2fe2-40af-9367-d86b8a31aa41",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episodes: 100 num_steps: 2285\n",
      "avg_length 22.85 avg_reward: 22.85\n"
     ]
    }
   ],
   "source": [
    "env = suite_gym.load(env_name)\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 100\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not time_step.is_last():\n",
    "        action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "        #print(action)\n",
    "        time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        episode_reward += time_step.reward.numpy()\n",
    "    rewards.append(episode_reward)\n",
    "    steps.append(episode_steps)\n",
    "    time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa727e9e-5d0d-40a6-bf70-e342c028e46e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing Q Policy libraries for creating a Q network for policies\n",
    "    # Agents trained will be based on Deep Q-Learning network (DQN)\n",
    "    # Q is quality of given moves\n",
    "    # It Predicts Q value for each discrete action Q: State * Action --> Reward.\n",
    "    # Bellman equation is a detailed explanation of this algorithm\n",
    "![](bellman.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8168b328-1451-492b-8bc0-94eb8faa19b5",
   "metadata": {
    "id": "34a47666-cc21-4ad8-9d54-52b0c39dc5d8"
   },
   "outputs": [],
   "source": [
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import network\n",
    "from tf_agents.policies import q_policy\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9faf7ae0-71aa-4db0-bc17-4f5a118daf07",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundedTensorSpec(shape=(), dtype=tf.int32, name=None, minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)) \n",
      "\n",
      " Number of actions: \t 2\n"
     ]
    }
   ],
   "source": [
    "input_tensor_spec = tensor_spec.TensorSpec((4,), tf.float32)\n",
    "time_step_spec = ts.time_step_spec(input_tensor_spec)\n",
    "action_spec = tensor_spec.BoundedTensorSpec((),\n",
    "                                            tf.int32,\n",
    "                                            minimum=0,\n",
    "                                            maximum=1)\n",
    "\n",
    "num_actions = action_spec.maximum - action_spec.minimum + 1\n",
    "print(action_spec, \"\\n\\n Number of actions: \\t\", num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4f99fc4-f9e5-4bd5-a8cb-42d466e6d95c",
   "metadata": {
    "id": "f55b5075-2f22-459c-9d9c-fa34091387bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int32)\n",
      "Action distribution:\n",
      "tfp.distributions.Categorical(\"Categorical\", batch_shape=[2], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "class QNetwork(network.Network):\n",
    "\n",
    "    def __init__(self, input_tensor_spec, action_spec, num_actions=num_actions, name=None):\n",
    "        super(QNetwork, self).__init__(\n",
    "            input_tensor_spec=input_tensor_spec,\n",
    "            state_spec=(),\n",
    "            name=name)\n",
    "        self._sub_layers = [\n",
    "            tf.keras.layers.Dense(num_actions),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, step_type=None, network_state=()):\n",
    "        del step_type\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        for layer in self._sub_layers:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs, network_state\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "observation = tf.ones([batch_size] + time_step_spec.observation.shape.as_list())\n",
    "time_steps = ts.restart(observation, batch_size=batch_size)\n",
    "\n",
    "my_q_network = QNetwork(\n",
    "    input_tensor_spec=input_tensor_spec,\n",
    "    action_spec=action_spec)\n",
    "\n",
    "my_q_policy = q_policy.QPolicy(\n",
    "    time_step_spec, action_spec, q_network=my_q_network)\n",
    "\n",
    "action_step = my_q_policy.action(time_steps)\n",
    "distribution_step = my_q_policy.distribution(time_steps)\n",
    "\n",
    "print('Action:')\n",
    "print(action_step.action)\n",
    "\n",
    "print('Action distribution:')\n",
    "print(distribution_step.action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d05597-9901-4e46-93dd-2ccedd1b3b27",
   "metadata": {
    "id": "8e1b65d6-6e11-4280-b836-585d0e2fb079"
   },
   "source": [
    "### Importing TensorFlow Drivers\n",
    "    # There are 2 types of drivers\n",
    "    # DynamicStepDriver, which terminates after a given number of (valid) environment steps\n",
    "    # DynamicEpisodeDriver, which terminates after a given number of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8c20b12-4145-40f0-9b15-7bef11231116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.drivers import dynamic_episode_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57c53ba8-d9e4-42c4-942e-7a48f356976c",
    "outputId": "03bb33c1-65f9-4f09-917e-6a72e61b6442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_time_step TimeStep(\n",
      "{'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
      " 'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
      "array([[-0.02324141, -0.01008724, -0.00878966,  0.04441485]],\n",
      "      dtype=float32)>,\n",
      " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
      " 'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>})\n",
      "Number of Steps:  4207\n",
      "Number of Episodes:  100\n",
      "policy_state ()\n"
     ]
    }
   ],
   "source": [
    "num_episodes = tf_metrics.NumberOfEpisodes()\n",
    "env_steps = tf_metrics.EnvironmentSteps()\n",
    "observers = [num_episodes, env_steps]\n",
    "\n",
    "driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    tf_env, my_q_policy, observers, num_episodes=100)\n",
    "\n",
    "# Initial driver.run will reset the environment and initialize the policy.\n",
    "final_time_step, policy_state = driver.run()\n",
    "\n",
    "print('final_time_step', final_time_step)\n",
    "print('Number of Steps: ', env_steps.result().numpy())\n",
    "print('Number of Episodes: ', num_episodes.result().numpy())\n",
    "print('policy_state', policy_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f1c96-4304-44ea-98f6-ed2ade524186",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "IAYGWxX3E8-n",
    "outputId": "294924fc-0db9-4e90-85f2-11e18c8885fb",
    "tags": []
   },
   "source": [
    "### Importing Replay Buffers\n",
    "    # replay buffers are used to store trajectories of experience when executing a policy in an environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d910dae7-45a6-4a2b-89fa-2711f377e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks import q_network\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7b75b466-089d-4c3c-84cf-b1782ac11c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_net = q_network.QNetwork(\n",
    "    tf_env.time_step_spec().observation,\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=(100,))\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(0.001))\n",
    "\n",
    "replay_buffer_capacity = 1000\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "# Add an observer that adds to the replay buffer:\n",
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "collect_steps_per_iteration = 10\n",
    "collect_op = dynamic_step_driver.DynamicStepDriver(\n",
    "  tf_env,\n",
    "  agent.collect_policy,\n",
    "  observers=replay_observer,\n",
    "  num_steps=collect_steps_per_iteration).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b38c71a-1d1c-4c75-9625-e41963e62d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[-0.04476987, -0.01103813,  0.02933757,  0.06541613]],\n",
       "       dtype=float32)>,\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8428cbb-fdd4-4048-8379-d963aabf9fbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Above all cells where the basic idea of building a network and training an agent, Now we proceed by putting all together from tensorflow documentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8cca5-bf2c-4eb2-953b-24b7b1e66357",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing libraries for training the DQN C51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "33fee400-5ce1-4ae2-afe8-3f9b5ad0eb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import categorical_q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00059a4-1019-4c85-81db-ff1192ceb3c2",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ecda9124-69b6-42e7-a4e9-4db992279094",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\" # @param {type:\"string\"}\n",
    "num_iterations = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "gamma = 0.99\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_atoms = 51  # @param {type:\"integer\"}\n",
    "min_q_value = -20  # @param {type:\"integer\"}\n",
    "max_q_value = 20  # @param {type:\"integer\"}\n",
    "n_step_update = 2  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 500  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "69493925-55d0-4753-985e-a3f7ff80b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "87481546-0469-47c4-a250-f3576c246509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.04355508, -0.01743631, -0.04003309, -0.03152977], dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "#PIL.Image.fromarray(env.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "01648881-a593-4ab0-b39a-8fa3a1bd19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f9c97e90-be53-4cc0-b4e5-640e7f3e60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4d2c4718-599d-4b39-81ef-7a6503d388b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7a68af7d-a997-4aa5-bbcb-ed531a1a9e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f4a06707-9c14-402b-b488-c3f18e73ae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.01108351,  0.04902146, -0.01056275, -0.03311269], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.01206393,  0.24429327, -0.011225  , -0.32910946], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:',)\n",
    "print(time_step, end=\"\\n\\n\")\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "eb90c9c9-7e85-4271-bec0-b789f945250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fdfe4de6-b1c9-4425-a564-ab07f350cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_q_net = categorical_q_network.CategoricalQNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    num_atoms=num_atoms,\n",
    "    fc_layer_params=fc_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f5f8be9c-78d3-44ca-ad6f-4f02a141d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = categorical_dqn_agent.CategoricalDqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    categorical_q_network=categorical_q_net,\n",
    "    optimizer=optimizer,\n",
    "    min_q_value=min_q_value,\n",
    "    max_q_value=max_q_value,\n",
    "    n_step_update=n_step_update,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    gamma=gamma,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "82b38e1f-df96-46ae-9d7d-f00ece02da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ae88a-a27c-442f-927e-90fc0405b068",
   "metadata": {},
   "source": [
    "#### Method to compute the average returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "148e6a2c-2431-4b89-ac1a-ceab7f7fcc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial return avg:  19.6\n"
     ]
    }
   ],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "initial_avg = compute_avg_return(eval_env, random_policy, num_eval_episodes)\n",
    "print(\"Initial return avg: \",initial_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b4420-5d47-4db9-bac2-9499348bac70",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8ed9d975-aafe-48b7-b4ad-81fa7ce57168",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "def collect_step(environment, policy):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    # Add trajectory to the replay buffer\n",
    "    replay_buffer.add_batch(traj)\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "    collect_step(train_env, random_policy)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations of\n",
    "# these. For more details see the drivers module.\n",
    "\n",
    "# Dataset generates trajectories with shape [BxTx...] where\n",
    "# T = n_step_update + 1.\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "    num_steps=n_step_update + 1).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e2d999fa-68b5-4768-903a-8cbca71d7485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'action': TensorSpec(shape=(64, 3), dtype=tf.int64, name=None),\n",
       "  'discount': TensorSpec(shape=(64, 3), dtype=tf.float32, name=None),\n",
       "  'next_step_type': TensorSpec(shape=(64, 3), dtype=tf.int32, name=None),\n",
       "  'observation': TensorSpec(shape=(64, 3, 4), dtype=tf.float32, name=None),\n",
       "  'policy_info': (),\n",
       "  'reward': TensorSpec(shape=(64, 3), dtype=tf.float32, name=None),\n",
       "  'step_type': TensorSpec(shape=(64, 3), dtype=tf.int32, name=None)}),\n",
       " BufferInfo(ids=TensorSpec(shape=(64, 3), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(64,), dtype=tf.float32, name=None)))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca418aa-1e1b-4c3e-aa67-a6090a8b0702",
   "metadata": {},
   "source": [
    "#### Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e7dce080-4688-4699-9213-35b0d5856e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 3.226306915283203\n",
      "step = 400: loss = 2.6565918922424316\n",
      "step = 500: Average Return = 56.30\n",
      "step = 600: loss = 2.4039156436920166\n",
      "step = 800: loss = 1.814502239227295\n",
      "step = 1000: loss = 2.033717632293701\n",
      "step = 1000: Average Return = 103.20\n",
      "step = 1200: loss = 1.5754903554916382\n",
      "step = 1400: loss = 1.8221116065979004\n",
      "step = 1500: Average Return = 168.30\n",
      "step = 1600: loss = 1.6192775964736938\n",
      "step = 1800: loss = 1.3451967239379883\n",
      "step = 2000: loss = 1.3876640796661377\n",
      "step = 2000: Average Return = 196.00\n",
      "step = 2200: loss = 1.2669364213943481\n",
      "step = 2400: loss = 1.412373423576355\n",
      "step = 2500: Average Return = 183.40\n",
      "step = 2600: loss = 1.1713130474090576\n",
      "step = 2800: loss = 0.9718074798583984\n",
      "step = 3000: loss = 1.0129733085632324\n",
      "step = 3000: Average Return = 118.10\n",
      "step = 3200: loss = 0.9876408576965332\n",
      "step = 3400: loss = 0.7824896574020386\n",
      "step = 3500: Average Return = 178.30\n",
      "step = 3600: loss = 1.067671298980713\n",
      "step = 3800: loss = 0.9727293848991394\n",
      "step = 4000: loss = 0.945029079914093\n",
      "step = 4000: Average Return = 167.20\n",
      "step = 4200: loss = 0.86594557762146\n",
      "step = 4400: loss = 1.009948492050171\n",
      "step = 4500: Average Return = 182.00\n",
      "step = 4600: loss = 1.0143706798553467\n",
      "step = 4800: loss = 0.6014062166213989\n",
      "step = 5000: loss = 0.6596794724464417\n",
      "step = 5000: Average Return = 186.60\n",
      "step = 5200: loss = 0.8533698916435242\n",
      "step = 5400: loss = 0.6299742460250854\n",
      "step = 5500: Average Return = 177.20\n",
      "step = 5600: loss = 0.7062277793884277\n",
      "step = 5800: loss = 0.6887590885162354\n",
      "step = 6000: loss = 0.870210587978363\n",
      "step = 6000: Average Return = 194.30\n",
      "step = 6200: loss = 0.6348013281822205\n",
      "step = 6400: loss = 0.8373929262161255\n",
      "step = 6500: Average Return = 190.90\n",
      "step = 6600: loss = 0.9260103106498718\n",
      "step = 6800: loss = 0.6436033248901367\n",
      "step = 7000: loss = 0.7114783525466919\n",
      "step = 7000: Average Return = 198.50\n",
      "step = 7200: loss = 0.5749591588973999\n",
      "step = 7400: loss = 0.5266560912132263\n",
      "step = 7500: Average Return = 186.90\n",
      "step = 7600: loss = 0.6072045564651489\n",
      "step = 7800: loss = 0.5665903091430664\n",
      "step = 8000: loss = 0.6535509824752808\n",
      "step = 8000: Average Return = 186.70\n",
      "step = 8200: loss = 0.6373255848884583\n",
      "step = 8400: loss = 0.531886637210846\n",
      "step = 8500: Average Return = 188.70\n",
      "step = 8600: loss = 0.5039195418357849\n",
      "step = 8800: loss = 0.5749309062957764\n",
      "step = 9000: loss = 0.5755726099014282\n",
      "step = 9000: Average Return = 188.20\n",
      "step = 9200: loss = 0.35154256224632263\n",
      "step = 9400: loss = 0.5099260807037354\n",
      "step = 9500: Average Return = 179.10\n",
      "step = 9600: loss = 0.7152481079101562\n",
      "step = 9800: loss = 0.5085787773132324\n",
      "step = 10000: loss = 0.5561689138412476\n",
      "step = 10000: Average Return = 189.60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience)\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "        \n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1:.2f}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4bbb5-f6de-4212-b691-88922828e034",
   "metadata": {},
   "source": [
    "#### Plotting the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1c946e6c-7380-4d23-9b16-273f0225ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.47499999999999964, 200.0)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "9641108f-aac1-44ca-a1bc-fcf5de13f23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comapring the Initial average: 19.600000381469727 \n",
      " and the final returned avergae:  189.60000610351562\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comapring the Initial average: {initial_avg} \\n and the final returned avergae:  {avg_return}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "openAIgym.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
